{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(df, continuous_features):\n",
    "    scaler = StandardScaler()\n",
    "    df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "    return df, scaler\n",
    "\n",
    "def one_hot_encode_features(df, categorical_features):\n",
    "    dummies = pd.get_dummies(df[categorical_features], drop_first=True, dtype=float)\n",
    "    df = df.join(dummies)\n",
    "    return df\n",
    "\n",
    "def compute_metrics(preds, targets):\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    targets = targets.detach().cpu().numpy()\n",
    "    mae = np.mean(np.abs(preds - targets))\n",
    "    rmse = np.sqrt(np.mean((preds - targets)**2))\n",
    "    ss_res = np.sum((targets - preds)**2)\n",
    "    ss_tot = np.sum((targets - np.mean(targets))**2)\n",
    "    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
    "    return mae, rmse, r2\n",
    "\n",
    "def assign_game_index(df):\n",
    "    # If your dataset contains a unique GAME-ID column, use it. Otherwise, use TEAM and DATE.\n",
    "    if 'GAME-ID' in df.columns:\n",
    "        unique_games = df[['TEAM', 'GAME-ID', 'DATE']].drop_duplicates().sort_values(by=['TEAM', 'DATE'])\n",
    "        unique_games['game_index'] = unique_games.groupby('TEAM').cumcount()\n",
    "        # Merge back the game_index onto the original DataFrame\n",
    "        df = df.merge(unique_games[['TEAM', 'GAME-ID', 'game_index']], on=['TEAM', 'GAME-ID'], how='left')\n",
    "    else:\n",
    "        unique_games = df[['TEAM', 'DATE']].drop_duplicates().sort_values(by=['TEAM', 'DATE'])\n",
    "        unique_games['game_index'] = unique_games.groupby('TEAM').cumcount()\n",
    "        df = df.merge(unique_games[['TEAM', 'DATE', 'game_index']], on=['TEAM', 'DATE'], how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csvs\n",
    "df = pd.read_excel(r\"../historical_data/MLB-2023-Player-BoxScore-Dataset.xlsx\", skiprows=[0])\n",
    "df2 = pd.read_excel(r\"../historical_data/MLB-2024-Player-BoxScore-Dataset.xlsx\", skiprows=[0])\n",
    "dfs = [df, df2]\n",
    "\n",
    "batter_features = ['game_index', 'DATE', 'PLAYER', 'TEAM',\n",
    "                    'VENUE', 'OPPONENT','AB', 'R', 'H', 'RBI',\n",
    "                    'BB', 'SO', 'next_target_H', \"PLAYER-ID\",\n",
    "                    'next_target_H', \"PLAYER-ID\", 'VENUE_Road',\n",
    "                    'opp_starting_pitcher', 'HAND_R']\n",
    "continuous_batter = ['AB', 'R', 'H', 'RBI', 'BB', 'SO']\n",
    "\n",
    "pitcher_features = ['game_index', 'DATE', 'PLAYER', 'TEAM',\n",
    "                    'VENUE', 'OPPONENT', 'IP', 'H.1', 'R.1',\n",
    "                    'ER', 'ERA', 'BB.1', 'SO.1', 'next_target_SO',\n",
    "                    \"PLAYER-ID\", 'VENUE_Road', 'HAND.1_R']\n",
    "continuous_pitcher = ['IP', 'H.1', 'R.1', 'ER', 'ERA', 'BB.1', 'SO.1']\n",
    "\n",
    "categorical_batter = ['VENUE', 'HAND']\n",
    "categorical_pitcher = ['VENUE','HAND.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split(df):\n",
    "    df.columns = df.columns.str.strip().str.replace('\"', '')\n",
    "\n",
    "    # Flag pitchers and set targets\n",
    "    df['is_pitcher'] = df['STARTING\\nPITCHER'].notnull()\n",
    "    df['target_SO'] = df.apply(lambda row: row[\"SO.1\"] if row['is_pitcher'] else row[\"SO\"], axis=1)\n",
    "    df['target_H']  = df.apply(lambda row: row[\"H.1\"] if row['is_pitcher'] else row[\"H\"], axis=1)\n",
    "\n",
    "    # Offset targets per player so current game features predict next game outcomes\n",
    "    df.sort_values([\"PLAYER-ID\", \"DATE\"], inplace=True)\n",
    "    df[\"next_target_SO\"] = df.groupby(\"PLAYER-ID\")[\"target_SO\"].shift(-1)\n",
    "    df[\"next_target_H\"]  = df.groupby(\"PLAYER-ID\")[\"target_H\"].shift(-1)\n",
    "    df = df.dropna(subset=[\"next_target_SO\", \"next_target_H\"])\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. Split into Pitchers and Batters\n",
    "    # -----------------------------\n",
    "    pitchers_df = df[df['is_pitcher']].copy()\n",
    "    batters_df = df[~df['is_pitcher']].copy()\n",
    "\n",
    "    return pitchers_df, batters_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_index(pitchers_df, batters_df):\n",
    "    pitchers_df['DATE'] = pd.to_datetime(pitchers_df['DATE'])\n",
    "    pitchers_df = assign_game_index(pitchers_df)\n",
    "\n",
    "    batters_df['DATE'] = pd.to_datetime(batters_df['DATE'])\n",
    "    batters_df = assign_game_index(batters_df)\n",
    "\n",
    "    # normalize numerical features\n",
    "    batters_df, batter_scaler = normalize_features(batters_df, continuous_batter)\n",
    "    pitchers_df, pitcher_scaler = normalize_features(pitchers_df, continuous_pitcher)\n",
    "\n",
    "    # one-hot encode categorical features\n",
    "    batters_df = one_hot_encode_features(batters_df, categorical_batter)\n",
    "    pitchers_df = one_hot_encode_features(pitchers_df, categorical_pitcher)\n",
    "\n",
    "    # save sklearn scalers\n",
    "    torch.save(batter_scaler, \"batter_scaler.pt\")\n",
    "    torch.save(pitcher_scaler, \"pitcher_scaler.pt\")\n",
    "\n",
    "    return pitchers_df, batters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_opps(pitchers_df, batters_df):\n",
    "    # Create a subset of the pitcher DataFrame with only the relevant columns.\n",
    "    # We assume 'TEAM' in pitchers_df is the pitcher's team and that each row is a starting pitcher.\n",
    "    # Rename the 'PLAYER-ID' column to something like 'opp_starting_pitcher' to clarify its role.\n",
    "    pitcher_lookup = pitchers_df[['GAME-ID', 'TEAM', 'DATE', 'PLAYER-ID']].copy()\n",
    "    pitcher_lookup = pitcher_lookup.rename(columns={\n",
    "        'TEAM': 'opp_team', \n",
    "        'PLAYER-ID': 'opp_starting_pitcher'\n",
    "    })\n",
    "\n",
    "    # Merge batter_df with pitcher_lookup based on the batter's opponent and the game date.\n",
    "    # This will add a new column 'opp_starting_pitcher' to batters_df.\n",
    "    batters_df = batters_df.merge(\n",
    "        pitcher_lookup[['opp_team', 'DATE', 'opp_starting_pitcher']], \n",
    "        left_on=['OPPONENT', 'DATE'], \n",
    "        right_on=['opp_team', 'DATE'], \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Optionally, drop the extra 'opp_team' column if you don't need it.\n",
    "    batters_df.drop(columns=['opp_team'], inplace=True)\n",
    "    batters_df['opp_starting_pitcher'].fillna(0, inplace=True)\n",
    "    batters_df['opp_starting_pitcher'] = batters_df['opp_starting_pitcher'].astype(int)\n",
    "    return pitchers_df, batters_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline these functions\n",
    "def preprocess(df):\n",
    "    pitchers_df, batters_df = clean_and_split(df)\n",
    "    pitchers_df, batters_df = normalize_and_index(pitchers_df, batters_df)\n",
    "    pitchers_df, batters_df = align_opps(pitchers_df, batters_df)\n",
    "    return pitchers_df, batters_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chcro\\AppData\\Local\\Temp\\ipykernel_7344\\273724753.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  batters_df['opp_starting_pitcher'].fillna(0, inplace=True)\n",
      "C:\\Users\\chcro\\AppData\\Local\\Temp\\ipykernel_7344\\273724753.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  batters_df['opp_starting_pitcher'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "pitcher_dfs = []\n",
    "batter_dfs = []\n",
    "for df in dfs:\n",
    "    pitcher_df, batter_df = preprocess(df)\n",
    "    pitcher_dfs.append(pitcher_df)\n",
    "    batter_dfs.append(batter_df)\n",
    "\n",
    "pitchers_df = pd.concat(pitcher_dfs)\n",
    "batters_df = pd.concat(batter_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135848, 19)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batters_df[batter_features].dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9399, 17)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitchers_df[pitcher_features].dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "batters_df[batter_features].dropna().to_csv(\"train_batters.csv\")\n",
    "pitchers_df[pitcher_features].dropna().to_csv(\"train_pitchers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
